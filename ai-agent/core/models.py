"""
SQLAlchemy data models for the AI Agent.

This module defines the schema for Scans, Findings, and user Feedback.
"""

from sqlalchemy import Column, Integer, String, Text, ForeignKey, Float, DateTime, Boolean
from sqlalchemy.orm import declarative_base, relationship
from datetime import datetime
from .database import Base
from pydantic import BaseModel

class Scan(Base):
    """
    Represents a single security scan execution on a project commit.
    """
    __tablename__ = "scans"
    
    id = Column(Integer, primary_key=True, index=True)
    project_name = Column(String, index=True) # e.g. "user/repo"
    commit_sha = Column(String, index=True)   # The Git commit hash scanned
    timestamp = Column(DateTime, default=datetime.utcnow)
    
    # Relationship to findings (One Scan -> Many Findings)
    findings = relationship("Finding", back_populates="scan")

class Finding(Base):
    """
    Represents a single security vulnerability/finding detected by a scanner tool.
    
    Stores both the original scanner data and the AI's subsequent analysis.
    """
    __tablename__ = "findings"
    
    id = Column(Integer, primary_key=True, index=True)
    scan_id = Column(Integer, ForeignKey("scans.id"))
    
    triage_decision = Column(String) # e.g., "TP" (True Positive) or "FP" (False Positive)
    sandbox_logs = Column(Text)      # Execution logs from the verification sandbox
    
    # --- SYNCHRONIZED FIELDS ---
    tool = Column(String)        # Name of the tool (Semgrep, Gitleaks, etc.)
    rule_id = Column(String)     # The specific rule violated
    file = Column(String)        # File path relative to repo root
    line = Column(Integer)       # Line number of the finding
    message = Column(Text)       # Original description from the scanner
    
    # --- AI & REMEDIATION FIELDS ---
    snippet = Column(Text)            # Code snippet extracted from source
    ai_verdict = Column(String)       # "TP" or "FP" determined by LLM
    ai_confidence = Column(Float)     # Confidence score (0.0 - 1.0) - unused currently
    ai_reasoning = Column(Text)       # LLM's explanation - unused currently
    ai_reasoning = Column(Text)       # LLM's explanation - unused currently
    risk_score = Column(Float)        # Numeric risk assessment (1.0 - 10.0)
    severity = Column(String)         # "Critical", "High", "Medium", "Low"
    remediation_patch = Column(Text)  # The code fix generated by the AI
    
    # --- AGENTIC OUTCOMES ---
    red_team_success = Column(Boolean, default=False) # Did the active exploit work?
    red_team_output = Column(Text)                    # Output from the exploit attempt
    pr_url = Column(String)                           # URL of the created Pull Request
    pr_error = Column(String)                         # Error message if PR creation failed
    
    # Relationships
    scan = relationship("Scan", back_populates="findings")
    feedbacks = relationship("Feedback", back_populates="finding")

class Feedback(Base):
    """
    Stores human feedback (RLHF) on AI decisions for future fine-tuning.
    """
    __tablename__ = "feedbacks"
    
    id = Column(Integer, primary_key=True, index=True)
    finding_id = Column(Integer, ForeignKey("findings.id"))
    
    user_verdict = Column(String) # The human's decision (True Positive/False Positive)
    comments = Column(Text)       # Optional educational context or correction
    timestamp = Column(DateTime, default=datetime.utcnow)
    
    # Relationship back to Finding
    finding = relationship("Finding", back_populates="feedbacks")

class FeedbackRequest(BaseModel):
    """
    Pydantic model for validating feedback API requests.
    """
    finding_id: int
    verdict: str
    comments: str

class PipelineMetric(Base):
    """
    Stores scalar metrics from CI/CD pipelines to train anomaly detection models.
    """
    __tablename__ = "pipeline_metrics"

    id = Column(Integer, primary_key=True, index=True)
    scan_id = Column(Integer, ForeignKey("scans.id"))

    build_duration_seconds = Column(Float, default=0.0)
    artifact_size_bytes = Column(Integer, default=0)
    num_changed_files = Column(Integer, default=0)
    test_coverage_percent = Column(Float, default=0.0)
    
    timestamp = Column(DateTime, default=datetime.utcnow)

    # Relationship
    scan = relationship("Scan", back_populates="metrics")

# Update Scan relationship
Scan.metrics = relationship("PipelineMetric", back_populates="scan", uselist=False)